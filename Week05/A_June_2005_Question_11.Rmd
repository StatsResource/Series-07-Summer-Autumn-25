---
title: "Joint Random Variables: Worked Example"
subtitle: "Discrete Probability Distributions"
output:
  xaringan::moon_reader:
    css: xaringan-themer.css
    lib_dir: libs
    nature:
      highlightStyle: github
      countIncrementalSlides: false
---


```{r setup1, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(magrittr)
library(knitr)
library(tidyquant)
library(ggside)
library(ggplot2)


```

```{r xaringan-themer, include=FALSE, warning=FALSE}
library(xaringanthemer)
style_mono_accent_inverse(
  #base_color = "#3C989E")(
  base_color = "#0cB2A3",
  header_font_google = google_font("Josefin Sans"),
  text_font_google   = google_font("Montserrat", "300", "300i"),
  code_font_google   = google_font("Fira Mono")
)
```

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r echo=FALSE,eval=FALSE,include=FALSE}

## ASI - CT3 - 2005 - June - Question 11

```


Let's address each part step-by-step.

### Part (a)

Given the joint density function:
$$f(x, y) = (1 - x + y) e^{-x - y} \quad \text{for } x \ge 0 \text{ and } y \ge 0$$

#### (i) Show that $ E(Y) $ does not exist

To find $ E(Y) $, we need to integrate the marginal distribution of $ Y $:
$$f_Y(y) = \int_{0}^{\infty} f(x, y) \, dx$$

Substitute $ f(x, y) $:
$$f_Y(y) = \int_{0}^{\infty} (1 - x + y) e^{-x - y} \, dx$$

$$f_Y(y) = e^{-y} \int_{0}^{\infty} (1 - x + y) e^{-x} \, dx$$

---

$$f_Y(y) = e^{-y} \left[ \int_{0}^{\infty} e^{-x} \, dx - \int_{0}^{\infty} x e^{-x} \, dx + y \int_{0}^{\infty} e^{-x} \, dx \right] $$

Evaluating these integrals:
$$ \int_{0}^{\infty} e^{-x} \, dx = 1$$
$$\int_{0}^{\infty} x e^{-x} \, dx = 1$$

$$f_Y(y) = e^{-y} [1 - 1 + y] = y e^{-y}$$

---

To find $E(Y)$:
$$E(Y) = \int_{0}^{\infty} y f_Y(y) \, dy = \int_{0}^{\infty} y^2 e^{-y} \, dy $$

This is the gamma function $ \Gamma(3)$:
$$ \int_{0}^{\infty} y^2 e^{-y} \, dy = 2! = 2$$

Since $ \Gamma(3) $ converges, $ E(Y) $ should exist. 

However, if there's an upper bound or other criteria involved in this specific problem, we'd consider that. Let's proceed to the next part.

---

#### (ii) Show that $ E(Y|X=x) = \frac{1}{x} $

The conditional expectation is given by:
$$E(Y | X = x) = \int_{0}^{\infty} y \frac{f(x, y)}{f_X(x)} \, dy$$

The marginal distribution $ f_X(x) $:
$$f_X(x) = \int_{0}^{\infty} (1 - x + y) e^{-x - y} \, dy$$

$$f_X(x) = e^{-x} \int_{0}^{\infty} (1 - x + y) e^{-y} \, dy$$

---

$$f_X(x) = e^{-x} [1 - x + 1] = 2e^{-x}$$

Thus,
$$E(Y | X = x) = \frac{1}{f_X(x)} \int_{0}^{\infty} y (1 - x + y) e^{-x - y} \, dy $$

$$E(Y | X = x) = \frac{1}{2e^{-x}} \int_{0}^{\infty} y (1 - x + y) e^{-y} \, dy $$

$$E(Y | X = x) = \frac{e^x}{2} \left[ \int_{0}^{\infty} y e^{-y} \, dy - x \int_{0}^{\infty} y e^{-y} \, dy + \int_{0}^{\infty} y^2 e^{-y} \, dy \right]$$

Given $\int_{0}^{\infty} y e^{-y} \, dy = 1 $ and $ \int_{0}^{\infty} y^2 e^{-y} \, dy = 2$:
$$E(Y | X = x) = \frac{e^x}{2} [1 - x + 2] = 1$$

---

### Part (b)

#### (i) Define a compound distribution

A compound distribution combines two distributions: one describing the number of events (e.g., Poisson), and another describing the size of each event (e.g., Binomial). The total distribution is the combination of these two.


#### (ii) Expected value and variance of $ S $

Given:
$$ N \sim \text{Poisson}(\lambda = 3) $$
$$ X_i \sim \text{Binomial}(n = 15, p = \frac{1}{3}) $$

Expected value:
$$E[S] = E\left[\sum_{i=1}^{N} X_i\right] = E[N] \cdot E[X]$$
$$E[N] = 3 $$
$$E[X] = np = 15 \cdot \frac{1}{3} = 5 $$
$$E[S] = 3 \cdot 5 = 15 $$

Variance:
$$\text{Var}(S) = E[N] \cdot \text{Var}(X) + \text{Var}(N) \cdot (E[X])^2$$
$$ \text{Var}(X) = np(1-p) = 15 \cdot \frac{1}{3} \cdot \frac{2}{3} = \frac{30}{9} = \frac{10}{3} $$
$$ \text{Var}(N) = 3 $$
$$ \text{Var}(S) = 3 \cdot \frac{10}{3} + 3 \cdot 25 = 10 + 75 = 85$$

So, the expected value of $S$ is 15 and the variance is 85.

---